{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stretching the cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# cuda settings\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = slim.nets.vgg.vgg_16.default_image_size\n",
    "num_classes = 2\n",
    "num_channels = 3\n",
    "train_data_path = \"catvdog_train.tfrecords\"\n",
    "valid_data_path = \"catvdog_valid.tfrecords\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg = slim.nets.vgg\n",
    "# x = tf.placeholder(tf.float32,[None,224,224,3])\n",
    "# with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "#     _,_ = vgg.vgg_16(x,100)\n",
    "# slim.get_variables_to_restore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path,num_epochs,batch_size):\n",
    "    feature = {'image':tf.FixedLenFeature([],tf.string), 'label':tf.FixedLenFeature([],tf.int64)}\n",
    "    with tf.name_scope('filename_queue'):\n",
    "        filename_queue = tf.train.string_input_producer([data_path],num_epochs=num_epochs)\n",
    "\n",
    "    with tf.name_scope('tfreader'):\n",
    "        reader = tf.TFRecordReader()\n",
    "        _,serialzed_example = reader.read(filename_queue)\n",
    "\n",
    "        features = tf.parse_single_example(serialzed_example,features=feature)\n",
    "\n",
    "    with tf.name_scope('input_editor'):\n",
    "        image = tf.decode_raw(features[\"image\"],tf.float32)\n",
    "        label = tf.cast(features[\"label\"],tf.int32)\n",
    "\n",
    "        image = tf.reshape(image,[image_size,image_size,num_channels])\n",
    "        label = tf.one_hot(label,depth=num_classes)\n",
    "    \n",
    "    with tf.name_scope('shufflreader'):\n",
    "        images,labels = tf.train.shuffle_batch([image,label],batch_size=batch_size,capacity=100,num_threads=4,min_after_dequeue=50)\n",
    "\n",
    "    return (images,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default graph.....\n",
      "\n",
      "Finalized the graph ... !\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "print(\"Loading default graph.....\")\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    model_path = \"./vgg_16.ckpt\"\n",
    "    assert(os.path.isfile(model_path))\n",
    "\n",
    "    # Defining the placeholder variables\n",
    "    with tf.name_scope('x_placeholders'):\n",
    "        x = tf.placeholder(tf.float32,shape=(None,image_size,image_size,3),name='x_true')\n",
    "    with tf.name_scope('y_placeholders'):\n",
    "        y = tf.placeholder(tf.int32,shape=(None,num_classes),name='y_true')\n",
    "    \n",
    "    # loading the vgg graph\n",
    "    vgg = slim.nets.vgg\n",
    "    with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=0.0001)):\n",
    "        logits,end_points = vgg.vgg_16(x,num_classes=num_classes,is_training=True)\n",
    "        \n",
    "        \n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "    init_fn = slim.assign_from_checkpoint_fn(model_path,variables_to_restore)\n",
    "\n",
    "    with tf.name_scope('last_layer_variables'):\n",
    "        fc8_variables = slim.get_variables('vgg_16/fc8')\n",
    "        fc8_init = tf.variables_initializer(fc8_variables)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=y))\n",
    "\n",
    "    with tf.name_scope('last_layer_optimizer'):\n",
    "        fc8_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        fc8_train_op = fc8_optimizer.minimize(loss,var_list=[fc8_variables])\n",
    "\n",
    "    with tf.name_scope('full_optimizer'):\n",
    "        full_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001)\n",
    "        full_train_op = full_optimizer.minimize(loss)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    with tf.name_scope('prediction'):\n",
    "        y_pred = tf.nn.softmax(logits,name='y_pred')\n",
    "        # actual output\n",
    "        actual = tf.argmax(y,1)\n",
    "        # predicted output\n",
    "        prediction = tf.argmax(y_pred,1)\n",
    "        \n",
    "#     writer=tf.summary.FileWriter('./catvdoggraph/')\n",
    "#     writer.add_graph(graph)\n",
    "    # tf.get_default_graph().finalize()  \n",
    "    \n",
    "    print(\"\\nFinalized the graph ... !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vgg_16.ckpt\n",
      "\n",
      "  Started Retraining ... !\n",
      "\n",
      "Validation Accuracy after retraining for 1 epoch : 0.50\n",
      "Validation Accuracy after retraining for 101 epoch : 0.36\n",
      "Validation Accuracy after retraining for 201 epoch : 0.67\n",
      "Validation Accuracy after retraining for 301 epoch : 0.77\n",
      "Validation Accuracy after retraining for 401 epoch : 0.37\n",
      "\n",
      "  Started Fine Tuning .... !\n",
      "\n",
      "Validation accuracy after fune tuning for 1 epoch : 0.8600000143051147\n",
      "Validation accuracy after fune tuning for 101 epoch : 0.8299999833106995\n",
      "Validation accuracy after fune tuning for 201 epoch : 0.6700000166893005\n",
      "Validation accuracy after fune tuning for 301 epoch : 0.8100000023841858\n",
      "Validation accuracy after fune tuning for 401 epoch : 0.8600000143051147\n",
      "Validation accuracy after fune tuning for 501 epoch : 0.7799999713897705\n",
      "Validation accuracy after fune tuning for 601 epoch : 0.9100000262260437\n",
      "Validation accuracy after fune tuning for 701 epoch : 0.8999999761581421\n",
      "Validation accuracy after fune tuning for 801 epoch : 0.949999988079071\n",
      "Validation accuracy after fune tuning for 901 epoch : 0.8700000047683716\n",
      "Validation accuracy after fune tuning for 1001 epoch : 0.9399999976158142\n",
      "Validation accuracy after fune tuning for 1101 epoch : 0.9200000166893005\n",
      "Validation accuracy after fune tuning for 1201 epoch : 0.8299999833106995\n",
      "Validation accuracy after fune tuning for 1301 epoch : 0.9300000071525574\n",
      "Validation accuracy after fune tuning for 1401 epoch : 0.9100000262260437\n",
      "Validation accuracy after fune tuning for 1501 epoch : 0.8600000143051147\n",
      "Validation accuracy after fune tuning for 1601 epoch : 0.9300000071525574\n",
      "Validation accuracy after fune tuning for 1701 epoch : 0.9599999785423279\n",
      "Validation accuracy after fune tuning for 1801 epoch : 0.9599999785423279\n",
      "Validation accuracy after fune tuning for 1901 epoch : 0.8899999856948853\n",
      "Validation accuracy after fune tuning for 2001 epoch : 0.9200000166893005\n",
      "Validation accuracy after fune tuning for 2101 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 2201 epoch : 0.8899999856948853\n",
      "Validation accuracy after fune tuning for 2301 epoch : 0.9399999976158142\n",
      "Validation accuracy after fune tuning for 2401 epoch : 0.9599999785423279\n",
      "Validation accuracy after fune tuning for 2501 epoch : 0.8999999761581421\n",
      "Validation accuracy after fune tuning for 2601 epoch : 0.9700000286102295\n",
      "Validation accuracy after fune tuning for 2701 epoch : 0.9399999976158142\n",
      "Validation accuracy after fune tuning for 2801 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 2901 epoch : 0.9100000262260437\n",
      "Validation accuracy after fune tuning for 3001 epoch : 0.949999988079071\n",
      "Validation accuracy after fune tuning for 3101 epoch : 0.9900000095367432\n",
      "Validation accuracy after fune tuning for 3201 epoch : 0.9300000071525574\n",
      "Validation accuracy after fune tuning for 3301 epoch : 0.9399999976158142\n",
      "Validation accuracy after fune tuning for 3401 epoch : 0.9100000262260437\n",
      "Validation accuracy after fune tuning for 3501 epoch : 0.9100000262260437\n",
      "Validation accuracy after fune tuning for 3601 epoch : 0.9700000286102295\n",
      "Validation accuracy after fune tuning for 3901 epoch : 0.9399999976158142\n",
      "Validation accuracy after fune tuning for 4001 epoch : 0.949999988079071\n",
      "Validation accuracy after fune tuning for 4101 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 4201 epoch : 0.9399999976158142\n",
      "Validation accuracy after fune tuning for 4301 epoch : 0.949999988079071\n",
      "Validation accuracy after fune tuning for 4401 epoch : 0.9399999976158142\n",
      "Validation accuracy after fune tuning for 4501 epoch : 0.9700000286102295\n",
      "Validation accuracy after fune tuning for 4601 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 4701 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 4801 epoch : 0.9900000095367432\n",
      "Validation accuracy after fune tuning for 4901 epoch : 0.9200000166893005\n",
      "Validation accuracy after fune tuning for 5001 epoch : 0.9599999785423279\n",
      "Validation accuracy after fune tuning for 5101 epoch : 0.9900000095367432\n",
      "Validation accuracy after fune tuning for 5201 epoch : 0.949999988079071\n",
      "Validation accuracy after fune tuning for 5301 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 5401 epoch : 0.9599999785423279\n",
      "Validation accuracy after fune tuning for 5501 epoch : 0.9200000166893005\n",
      "Validation accuracy after fune tuning for 5601 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 5701 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 5801 epoch : 0.9900000095367432\n",
      "Validation accuracy after fune tuning for 5901 epoch : 0.9100000262260437\n",
      "Validation accuracy after fune tuning for 6001 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 6101 epoch : 0.9700000286102295\n",
      "Validation accuracy after fune tuning for 6201 epoch : 0.949999988079071\n",
      "Validation accuracy after fune tuning for 6301 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 6401 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 6501 epoch : 0.9300000071525574\n",
      "Validation accuracy after fune tuning for 6601 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 6701 epoch : 0.9900000095367432\n",
      "Validation accuracy after fune tuning for 6801 epoch : 0.9900000095367432\n",
      "Validation accuracy after fune tuning for 6901 epoch : 0.9200000166893005\n",
      "Validation accuracy after fune tuning for 7001 epoch : 0.9399999976158142\n",
      "Validation accuracy after fune tuning for 7101 epoch : 0.9900000095367432\n",
      "Validation accuracy after fune tuning for 7201 epoch : 0.9700000286102295\n",
      "Validation accuracy after fune tuning for 7301 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 7401 epoch : 0.9700000286102295\n",
      "Validation accuracy after fune tuning for 7501 epoch : 0.9100000262260437\n",
      "Validation accuracy after fune tuning for 7601 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 7701 epoch : 1.0\n",
      "Validation accuracy after fune tuning for 7801 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 8101 epoch : 0.9900000095367432\n",
      "Validation accuracy after fune tuning for 8201 epoch : 0.9200000166893005\n",
      "Validation accuracy after fune tuning for 8301 epoch : 0.9599999785423279\n",
      "Validation accuracy after fune tuning for 8401 epoch : 0.9900000095367432\n",
      "Validation accuracy after fune tuning for 8501 epoch : 0.9300000071525574\n",
      "Validation accuracy after fune tuning for 8601 epoch : 0.9700000286102295\n",
      "Validation accuracy after fune tuning for 8701 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 8801 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 8901 epoch : 0.9200000166893005\n",
      "Validation accuracy after fune tuning for 9001 epoch : 0.9800000190734863\n",
      "Validation accuracy after fune tuning for 9101 epoch : 1.0\n",
      "Validation accuracy after fune tuning for 9201 epoch : 0.9700000286102295\n",
      "Validation accuracy after fune tuning for 9301 epoch : 0.9700000286102295\n",
      "Validation accuracy after fune tuning for 9401 epoch : 0.9900000095367432\n",
      "\n",
      " Finished Training .../\n"
     ]
    }
   ],
   "source": [
    "# checking if the convnet graph is same as the default graph\n",
    "assert logits.graph == graph\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph,config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    images,labels = read_data(train_data_path,num_epochs=100,batch_size=50)\n",
    "    valid_images,valid_labels = read_data(valid_data_path,num_epochs=50,batch_size=100)\n",
    "    \n",
    "    with tf.name_scope('initialization'):\n",
    "        init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())  \n",
    "        sess.run(init_op)\n",
    "\n",
    "        init_fn(sess)\n",
    "        sess.run(fc8_init)\n",
    "    \n",
    "    with tf.name_scope('multithreading'):\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(logdir='./catvdoggraph/',graph=sess.graph)\n",
    "\n",
    "    print(\"\\n  Started Retraining ... !\\n\")\n",
    "\n",
    "    # Retraining last layer...\n",
    "    \n",
    "    for epoch in range(500):\n",
    "        img,lbl = sess.run([images,labels])\n",
    "        img = img.astype(np.uint8)\n",
    "        sess.run(fc8_train_op,feed_dict={x:img,y:lbl})\n",
    "#         if(epoch%10 == 0):\n",
    "#             print(\"Loss after {} epoch : {:.2f}\".format(epoch,sess.run(loss,feed_dict={x:img,y:lbl})))\n",
    "        if(epoch %100 == 0):\n",
    "            val_img,val_lbl = sess.run([valid_images,valid_labels])\n",
    "            val_img = val_img.astype(np.uint8)\n",
    "            print(\"Validation Accuracy after retraining for {} epoch : {:.2f}\".format(epoch+1,sess.run(accuracy,feed_dict={x:val_img,y:val_lbl})))\n",
    "\n",
    "\n",
    "    print(\"\\n  Started Fine Tuning .... !\\n\")\n",
    "    # Fine tuning all layers\n",
    "    epoch=0\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            img,lbl = sess.run([images,labels])\n",
    "            sess.run(full_train_op,feed_dict={x:img,y:lbl})\n",
    "            if(epoch%100 == 0):\n",
    "#                 print(\"Loss after {} epoch : {}\".format(epoch,sess.run(loss,feed_dict={x:img,y:lbl})))\n",
    "                val_img,val_lbl = sess.run([valid_images,valid_labels])\n",
    "                print(\"Validation accuracy after fune tuning for {} epoch : {}\".format(epoch+1,sess.run(accuracy,feed_dict={x:val_img,y:val_lbl})))  \n",
    "            epoch+=1\n",
    "    except tf.errors.OutOfRangeError as e:\n",
    "        coord.request_stop(e)\n",
    "        \n",
    "    \n",
    "    saver.save(sess,'saved_models/catvdog.ckpt')\n",
    "\n",
    "    print(\"\\n Finished Training .../\")\n",
    "    writer.close()\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable               Type                        Data/Info\n",
      "------------------------------------------------------------\n",
      "HTML                   type                        <class 'IPython.core.display.HTML'>\n",
      "accuracy               Tensor                      Tensor(\"accuracy/Mean:0\",<...> shape=(), dtype=float32)\n",
      "actual                 Tensor                      Tensor(\"prediction/ArgMax<...> shape=(?,), dtype=int64)\n",
      "coord                  Coordinator                 <tensorflow.python.traini<...>object at 0x7f35e40e4748>\n",
      "correct_prediction     Tensor                      Tensor(\"accuracy/Equal:0\"<...>, shape=(?,), dtype=bool)\n",
      "display                function                    <function display at 0x7f369c891950>\n",
      "end_points             OrderedDict                 OrderedDict([('vgg_16/con<...>=(?, 8) dtype=float32>)])\n",
      "epoch                  int                         99\n",
      "fc8_init               Operation                   name: \"last_layer_variabl<...>g_16/fc8/biases/Assign\"\\n\n",
      "fc8_optimizer          GradientDescentOptimizer    <tensorflow.python.traini<...>object at 0x7f34ffbe58d0>\n",
      "fc8_train_op           Operation                   name: \"last_layer_optimiz<...>s/ApplyGradientDescent\"\\n\n",
      "fc8_variables          list                        n=2\n",
      "full_optimizer         GradientDescentOptimizer    <tensorflow.python.traini<...>object at 0x7f35a002d518>\n",
      "full_train_op          Operation                   name: \"full_optimizer/Gra<...>s/ApplyGradientDescent\"\\n\n",
      "gpu_options            GPUOptions                  per_process_gpu_memory_fraction: 0.5\\n\n",
      "graph                  Graph                       <tensorflow.python.framew<...>object at 0x7f35e4229208>\n",
      "image_size             int                         224\n",
      "images                 Tensor                      Tensor(\"shufflreader/shuf<...>, 224, 3), dtype=float32)\n",
      "img                    ndarray                     50x224x224x3: 7526400 elems, type `uint8`, 7526400 bytes (7.177734375 Mb)\n",
      "init_fn                function                    <function assign_from_che<...>llback at 0x7f35e4b10f28>\n",
      "init_op                Operation                   name: \"initialization/gro<...>^initialization/init_1\"\\n\n",
      "labels                 Tensor                      Tensor(\"shufflreader/shuf<...>e=(50, 8), dtype=float32)\n",
      "lbl                    ndarray                     50x8: 400 elems, type `float32`, 1600 bytes\n",
      "logits                 Tensor                      Tensor(\"vgg_16/fc8/squeez<...>pe=(?, 8), dtype=float32)\n",
      "loss                   Tensor                      Tensor(\"loss/Mean:0\", shape=(), dtype=float32)\n",
      "model_path             str                         ./vgg_16.ckpt\n",
      "np                     module                      <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "num_channels           int                         3\n",
      "num_classes            int                         8\n",
      "os                     module                      <module 'os' from '/usr/lib/python3.5/os.py'>\n",
      "plt                    module                      <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "prediction             Tensor                      Tensor(\"prediction/ArgMax<...> shape=(?,), dtype=int64)\n",
      "read_data              function                    <function read_data at 0x7f35e423da60>\n",
      "saver                  Saver                       <tensorflow.python.traini<...>object at 0x7f35dff172e8>\n",
      "sess                   Session                     <tensorflow.python.client<...>object at 0x7f353863b4e0>\n",
      "slim                   module                      <module 'tensorflow.contr<...>ontrib/slim/__init__.py'>\n",
      "tensorflow             module                      <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
      "tf                     module                      <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
      "threads                list                        n=14\n",
      "train_data_path        str                         catvdog_train.tfrecords\n",
      "val_img                ndarray                     100x224x224x3: 15052800 elems, type `uint8`, 15052800 bytes (14.35546875 Mb)\n",
      "val_lbl                ndarray                     100x8: 800 elems, type `float32`, 3200 bytes\n",
      "valid_data_path        str                         catvdog_valid.tfrecords\n",
      "valid_images           Tensor                      Tensor(\"shufflreader_1/sh<...>, 224, 3), dtype=float32)\n",
      "valid_labels           Tensor                      Tensor(\"shufflreader_1/sh<...>=(100, 8), dtype=float32)\n",
      "variables_to_restore   list                        n=30\n",
      "vgg                    module                      <module 'tensorflow.contr<...>python/slim/nets/vgg.py'>\n",
      "writer                 FileWriter                  <tensorflow.python.summar<...>object at 0x7f35dff173c8>\n",
      "x                      Tensor                      Tensor(\"x_placeholders/Pl<...>, 224, 3), dtype=float32)\n",
      "y                      Tensor                      Tensor(\"y_placeholders/Pl<...>hape=(?, 8), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-05-30 13:28:50.199752: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2018-05-30 13:28:51.288142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\n",
      "pciBusID: 0000:17:00.0\n",
      "totalMemory: 10.91GiB freeMemory: 145.38MiB\n",
      "2018-05-30 13:28:51.288197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\n",
      "2018-05-30 13:28:51.808954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-05-30 13:28:51.809016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \n",
      "2018-05-30 13:28:51.809034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \n",
      "\u001b[33mW0530 13:28:51.860686 Reloader tf_logging.py:121] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0m\u001b[33mW0530 13:28:51.862515 Reloader tf_logging.py:121] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0m\u001b[33mW0530 13:28:51.874658 Reloader tf_logging.py:121] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0m\u001b[33mW0530 13:28:51.876711 Reloader tf_logging.py:121] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0m\u001b[33mW0530 13:28:51.898404 Reloader tf_logging.py:121] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0m\u001b[33mW0530 13:28:51.901288 Reloader tf_logging.py:121] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0m\u001b[33mW0530 13:28:51.902389 Reloader tf_logging.py:121] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0mTensorBoard 1.8.0 at http://f7ac6128128e:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=\"./catvdoggraph/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
