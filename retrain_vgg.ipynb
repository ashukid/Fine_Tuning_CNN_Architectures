{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stretching the cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# cuda settings\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading then tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(data_path='train.tfrecords'):\n",
    "    data_path = \"train.tfrecords\"\n",
    "    feature = {'train/image':tf.FixedLenFeature([],tf.string), 'train/label':tf.FixedLenFeature([],tf.int64)}\n",
    "    filename_queue = tf.train.string_input_producer([data_path],num_epochs=10)\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialzed_example = reader.read(filename_queue)\n",
    "\n",
    "    features = tf.parse_single_example(serialzed_example,features=feature)\n",
    "\n",
    "    image = tf.decode_raw(features[\"train/image\"],tf.float32)\n",
    "    label = tf.cast(features[\"train/label\"],tf.int32)\n",
    "\n",
    "    image = tf.reshape(image,[224,224,3])\n",
    "    label = tf.one_hot(label,depth=8)\n",
    "    images,labels = tf.train.shuffle_batch([image,label],batch_size=100,capacity=100,num_threads=1,min_after_dequeue=10)\n",
    "\n",
    "    return (images,labels)\n",
    "    \n",
    "# init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_op)\n",
    "\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "#     for i in range(1):\n",
    "#         img,lbl = sess.run([images,labels])\n",
    "#         print(img.shape,lbl.shape)        \n",
    "#     coord.request_stop()\n",
    "\n",
    "#     coord.join(threads)\n",
    "#     sess.close()\n",
    "\n",
    "        \n",
    "# with tf.Session() as sess:\n",
    "#     images,labels = read_training_data()\n",
    "#     init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())  \n",
    "#     sess.run(init_op)\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "#     for i in range(1):\n",
    "#         i,l = sess.run([images,labels])\n",
    "#         i = i.astype(np.uint8)\n",
    "#         print(i.shape,l.shape)\n",
    "#         plt.imshow(i[99])\n",
    "#         plt.title(l[99])\n",
    "#         plt.show()\n",
    "        \n",
    "\n",
    "#     coord.request_stop()\n",
    "\n",
    "#     coord.join(threads)\n",
    "#     sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_validation_data(data_path='valid.tfrecords'):\n",
    "    data_path = \"valid.tfrecords\"\n",
    "    feature = {'valid/image':tf.FixedLenFeature([],tf.string), 'valid/label':tf.FixedLenFeature([],tf.int64)}\n",
    "    filename_queue = tf.train.string_input_producer([data_path],num_epochs=1)\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialzed_example = reader.read(filename_queue)\n",
    "\n",
    "    features = tf.parse_single_example(serialzed_example,features=feature)\n",
    "\n",
    "    image = tf.decode_raw(features[\"valid/image\"],tf.float32)\n",
    "    label = tf.cast(features[\"valid/label\"],tf.int32)\n",
    "\n",
    "    image = tf.reshape(image,[224,224,3])\n",
    "    label = tf.one_hot(label,depth=8)\n",
    "    images,labels = tf.train.shuffle_batch([image,label],batch_size=100,capacity=100,num_threads=1,min_after_dequeue=10)\n",
    "\n",
    "    return (images,labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default graph.....\n",
      "\n",
      "Finalized the graph ... !\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "print(\"Loading default graph.....\")\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    model_path = \"./vgg_16.ckpt\"\n",
    "    assert(os.path.isfile(model_path))\n",
    "\n",
    "    vgg = slim.nets.vgg\n",
    "    image_size = vgg.vgg_16.default_image_size\n",
    "    num_classes = 8\n",
    "    \n",
    "    x = tf.placeholder(tf.float32,shape=(None,image_size,image_size,3))\n",
    "    y = tf.placeholder(tf.int32,shape=(None,num_classes))\n",
    "    with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=0.0001)):\n",
    "        logits,end_points = vgg.vgg_16(x,num_classes=num_classes,is_training=True)\n",
    "        \n",
    "\n",
    "\n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "    init_fn = slim.assign_from_checkpoint_fn(model_path,variables_to_restore)\n",
    "\n",
    "    fc8_variables = slim.get_variables('vgg_16/fc8')\n",
    "    fc8_init = tf.variables_initializer(fc8_variables)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=y))\n",
    "\n",
    "    fc8_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    fc8_train_op = fc8_optimizer.minimize(loss,var_list=fc8_variables)\n",
    "\n",
    "    full_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001)\n",
    "    full_train_op = full_optimizer.minimize(loss)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    # actual = tf.argmax(y,1)\n",
    "    prediction = tf.argmax(logits,1)\n",
    "        \n",
    "    # tf.get_default_graph().finalize()  \n",
    "    \n",
    "    print(\"\\nFinalized the graph ... !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert logits.graph == graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vgg_16.ckpt\n",
      "Started Training ... !\n",
      "Loss : 1472.16\n",
      "Loss : 1259.70\n",
      "Loss : 2760.25\n",
      "Loss : 2103.44\n",
      "Loss : 2394.38\n",
      "Loss : 3645.92\n",
      "Loss : 3833.62\n",
      "Loss : 1626.60\n",
      "Loss : 1766.15\n",
      "Loss : 974.02\n",
      "Loss : 1511.09\n",
      "Loss : 1259.14\n",
      "Loss : 519.53\n",
      "Loss : 882.81\n",
      "Loss : 314.82\n",
      "Loss : 763.79\n",
      "Loss : 878.60\n",
      "Loss : 761.53\n",
      "Loss : 654.65\n",
      "Loss : 445.76\n",
      "Loss : 675.90\n",
      "Loss : 180.58\n",
      "Loss : 530.42\n",
      "Loss : 668.54\n",
      "Loss : 990.98\n",
      "Loss : 563.93\n",
      "Loss : 968.18\n",
      "Loss : 185.87\n",
      "Loss : 433.65\n",
      "Loss : 358.65\n",
      "Loss : 57.59\n",
      "Loss : 566.99\n",
      "Loss : 434.27\n",
      "Loss : 244.52\n",
      "Loss : 922.28\n",
      "Loss : 46.98\n",
      "Loss : 405.30\n",
      "Loss : 325.35\n",
      "Loss : 82.46\n",
      "Loss : 710.17\n",
      "Loss : 383.95\n",
      "Loss : 165.17\n",
      "Loss : 501.37\n",
      "Loss : 228.52\n",
      "Loss : 215.53\n",
      "Loss : 344.00\n",
      "Loss : 125.06\n",
      "Loss : 537.87\n",
      "Loss : 256.54\n",
      "Loss : 204.62\n",
      "Loss : 211.54\n",
      "Loss : 2.39\n",
      "Loss : 277.20\n",
      "Loss : 244.27\n",
      "Loss : 0.23\n",
      "Loss : 323.13\n",
      "Loss : 506.49\n",
      "Loss : 159.35\n",
      "Loss : 582.47\n",
      "Loss : 44.92\n",
      "Loss : 130.67\n",
      "Loss : 190.47\n",
      "Loss : 129.25\n",
      "Loss : 241.10\n",
      "Loss : 336.43\n",
      "Loss : 151.51\n",
      "Loss : 141.96\n",
      "Loss : 126.83\n",
      "Loss : 232.28\n",
      "Loss : 164.71\n",
      "Loss : 159.13\n",
      "Loss : 147.93\n",
      "Loss : 89.71\n",
      "Loss : 327.56\n",
      "Loss : 478.57\n",
      "Loss : 10.71\n",
      "Loss : 209.42\n",
      "Loss : 295.04\n",
      "Loss : 22.94\n",
      "Loss : 178.85\n",
      "Validation Accuracy after retraining for 80 epoch : 0.58\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph,config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    images,labels = read_training_data()\n",
    "    valid_images,valid_labels = read_validation_data()\n",
    "    \n",
    "    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())  \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    init_fn(sess)\n",
    "    sess.run(fc8_init)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    print(\"Started Training ... !\")\n",
    "\n",
    "    epoch=0\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            img,lbl = sess.run([images,labels])\n",
    "            img = img.astype(np.uint8)\n",
    "            # print(\"Next batch : {}\".format(img.shape,lbl.shape))\n",
    "            sess.run(fc8_train_op,feed_dict={x:img,y:lbl})\n",
    "            print(\"Loss : {:.2f}\".format(sess.run(loss,feed_dict={x:img,y:lbl})))\n",
    "            epoch+=1\n",
    "    except tf.errors.OutOfRangeError as e:\n",
    "        coord.request_stop(e)\n",
    "        \n",
    "    val_img,val_lbl = sess.run([valid_images,valid_labels])\n",
    "    val_img = val_img.astype(np.uint8)\n",
    "    print(\"Validation Accuracy after retraining for {} epoch : {:.2f}\".format(epoch,sess.run(accuracy,feed_dict={x:val_img,y:val_lbl})))\n",
    "    print(len(sess.run(prediction,feed_dict={x:val_img})))\n",
    "\n",
    "\n",
    "#     try:\n",
    "#         while not coord.should_stop():\n",
    "#             img,lbl = sess.run([images,labels])\n",
    "#             print(\"Next batch : {}\".format(img.shape,lbl.shape))\n",
    "#             sess.run(full_train_op)\n",
    "#     except tf.errors.OutOfRangeError as e:\n",
    "#         coord.request_stop(e)\n",
    "#     val_img,val_lbl = sess.run([valid_images,valid_labels])\n",
    "#     print(\"Validation accuracy after fune tuning : {}\".format(sess.run(accuracy)))  \n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
