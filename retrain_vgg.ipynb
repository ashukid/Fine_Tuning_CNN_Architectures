{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# stretching the cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# cuda settings\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading then tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(data_path='train.tfrecords'):\n",
    "    data_path = \"train.tfrecords\"\n",
    "    feature = {'train/image':tf.FixedLenFeature([],tf.string), 'train/label':tf.FixedLenFeature([],tf.int64)}\n",
    "    filename_queue = tf.train.string_input_producer([data_path],num_epochs=10)\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialzed_example = reader.read(filename_queue)\n",
    "\n",
    "    features = tf.parse_single_example(serialzed_example,features=feature)\n",
    "\n",
    "    image = tf.decode_raw(features[\"train/image\"],tf.float32)\n",
    "    label = tf.cast(features[\"train/label\"],tf.int32)\n",
    "\n",
    "    image = tf.reshape(image,[224,224,3])\n",
    "    label = tf.one_hot(label,depth=8)\n",
    "    images,labels = tf.train.shuffle_batch([image,label],batch_size=10,capacity=100,num_threads=1,min_after_dequeue=10)\n",
    "\n",
    "    return (images,labels)\n",
    "    \n",
    "# init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_op)\n",
    "\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "#     for i in range(1):\n",
    "#         img,lbl = sess.run([images,labels])\n",
    "#         print(img.shape,lbl.shape)        \n",
    "#     coord.request_stop()\n",
    "\n",
    "#     coord.join(threads)\n",
    "#     sess.close()\n",
    "\n",
    "        \n",
    "# with tf.Session() as sess:\n",
    "#     images,labels = read_training_data()\n",
    "#     init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())  \n",
    "#     sess.run(init_op)\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "#     for i in range(1):\n",
    "#         i,l = sess.run([images,labels])\n",
    "#         i = i.astype(np.uint8)\n",
    "#         print(i.shape,l.shape)\n",
    "#         plt.imshow(i[99])\n",
    "#         plt.title(l[99])\n",
    "#         plt.show()\n",
    "        \n",
    "\n",
    "#     coord.request_stop()\n",
    "\n",
    "#     coord.join(threads)\n",
    "#     sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_validation_data(data_path='valid.tfrecords'):\n",
    "    data_path = \"valid.tfrecords\"\n",
    "    feature = {'valid/image':tf.FixedLenFeature([],tf.string), 'valid/label':tf.FixedLenFeature([],tf.int64)}\n",
    "    filename_queue = tf.train.string_input_producer([data_path],num_epochs=2)\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialzed_example = reader.read(filename_queue)\n",
    "\n",
    "    features = tf.parse_single_example(serialzed_example,features=feature)\n",
    "\n",
    "    image = tf.decode_raw(features[\"valid/image\"],tf.float32)\n",
    "    label = tf.cast(features[\"valid/label\"],tf.int32)\n",
    "\n",
    "    image = tf.reshape(image,[224,224,3])\n",
    "    label = tf.one_hot(label,depth=8)\n",
    "    images,labels = tf.train.shuffle_batch([image,label],batch_size=100,capacity=100,num_threads=1,min_after_dequeue=10)\n",
    "\n",
    "    return (images,labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default graph.....\n",
      "\n",
      "Finalized the graph ... !\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "print(\"Loading default graph.....\")\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    model_path = \"./vgg_16.ckpt\"\n",
    "    assert(os.path.isfile(model_path))\n",
    "\n",
    "    vgg = slim.nets.vgg\n",
    "    image_size = vgg.vgg_16.default_image_size\n",
    "    num_classes = 8\n",
    "    \n",
    "    x = tf.placeholder(tf.float32,shape=(None,image_size,image_size,3))\n",
    "    y = tf.placeholder(tf.int32,shape=(None,num_classes))\n",
    "    with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=0.0001)):\n",
    "        logits,end_points = vgg.vgg_16(x,num_classes=num_classes,is_training=True)\n",
    "        \n",
    "\n",
    "\n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "    init_fn = slim.assign_from_checkpoint_fn(model_path,variables_to_restore)\n",
    "\n",
    "    fc8_variables = slim.get_variables('vgg_16/fc8')\n",
    "    fc8_init = tf.variables_initializer(fc8_variables)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=y))\n",
    "\n",
    "    fc8_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    fc8_train_op = fc8_optimizer.minimize(loss,var_list=fc8_variables)\n",
    "\n",
    "    full_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001)\n",
    "    full_train_op = full_optimizer.minimize(loss)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    # actual = tf.argmax(y,1)\n",
    "    prediction = tf.argmax(logits,1)\n",
    "        \n",
    "    # tf.get_default_graph().finalize()  \n",
    "    \n",
    "    print(\"\\nFinalized the graph ... !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert logits.graph == graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vgg_16.ckpt\n",
      "Started Training ... !\n",
      "Validation Accuracy after retraining for 10 epoch : 0.30\n",
      "0.46884537\n",
      "1.5828413\n",
      "2.3210912\n",
      "2.2102864\n",
      "2.2987585\n",
      "1.2344649\n",
      "2.1070848\n",
      "3.1716313\n",
      "1.7021847\n",
      "2.767602\n",
      "2.4365942\n",
      "1.8044657\n",
      "2.1472318\n",
      "1.8912977\n",
      "2.0627327\n",
      "1.0303156\n",
      "2.0095344\n",
      "2.257977\n",
      "2.6861587\n",
      "2.2281647\n",
      "1.9058971\n",
      "2.0741856\n",
      "2.0520089\n",
      "2.3768961\n",
      "1.4404333\n",
      "1.4544898\n",
      "2.0863311\n",
      "1.0653149\n",
      "0.9906745\n",
      "2.4846907\n",
      "2.5362048\n",
      "3.377974\n",
      "3.7686772\n",
      "1.5588417\n",
      "2.1459813\n",
      "1.6524994\n",
      "2.5544462\n",
      "1.9462707\n",
      "1.7321975\n",
      "2.8573623\n",
      "3.7788315\n",
      "4.263249\n",
      "2.495042\n",
      "3.1601462\n",
      "2.0745957\n",
      "2.1103022\n",
      "1.700491\n",
      "1.6294644\n",
      "0.64711\n",
      "2.2953496\n",
      "3.3453434\n",
      "3.0266688\n",
      "1.7607622\n",
      "1.8391562\n",
      "1.796822\n",
      "2.1103806\n",
      "0.9485003\n",
      "1.0519779\n",
      "0.29233357\n",
      "2.2365055\n",
      "2.4635212\n",
      "2.7278972\n",
      "2.8366249\n",
      "3.3455043\n",
      "1.7363584\n",
      "1.2423923\n",
      "1.730862\n",
      "1.6742408\n",
      "1.2506138\n",
      "1.5817688\n",
      "1.5059102\n",
      "1.4719489\n",
      "1.7848917\n",
      "2.1006875\n",
      "1.4042399\n",
      "1.5329721\n",
      "0.72922754\n",
      "0.66675574\n",
      "1.0329626\n",
      "1.5857325\n",
      "1.5467293\n",
      "1.5266397\n",
      "2.1878617\n",
      "1.2033187\n",
      "1.6394527\n",
      "1.0183895\n",
      "1.2504276\n",
      "0.85384595\n",
      "1.0330837\n",
      "1.4145002\n",
      "1.9414527\n",
      "2.084597\n",
      "2.1316159\n",
      "1.9241349\n",
      "1.689934\n",
      "2.2008483\n",
      "2.021054\n",
      "1.5897601\n",
      "1.0643224\n",
      "1.9842141\n",
      "1.9302912\n",
      "1.7239422\n",
      "2.0267901\n",
      "1.9685736\n",
      "1.216315\n",
      "1.5192057\n",
      "1.6165264\n",
      "0.8754206\n",
      "1.1660055\n",
      "2.4292846\n",
      "1.946454\n",
      "1.9979855\n",
      "1.533988\n",
      "2.5058966\n",
      "1.6826853\n",
      "1.9716587\n",
      "1.994202\n",
      "1.2673105\n",
      "1.7692156\n",
      "1.7308781\n",
      "1.3633053\n",
      "1.8626919\n",
      "1.6010603\n",
      "1.6703987\n",
      "0.69802725\n",
      "0.9791729\n",
      "1.3614626\n",
      "0.6401521\n",
      "0.7659933\n",
      "0.82561475\n",
      "1.5705525\n",
      "1.1943944\n",
      "0.8033141\n",
      "0.52362186\n",
      "0.2072922\n",
      "0.70391417\n",
      "0.53579205\n",
      "0.491215\n",
      "0.034135424\n",
      "1.1863601\n",
      "1.2026799\n",
      "1.5063312\n",
      "2.2812715\n",
      "1.6800878\n",
      "1.0496451\n",
      "1.1461298\n",
      "1.4339168\n",
      "1.3081024\n",
      "0.27188253\n",
      "1.825621\n",
      "1.9241394\n",
      "1.1748149\n",
      "1.1217616\n",
      "1.195054\n",
      "1.4771204\n",
      "0.925457\n",
      "1.0931723\n",
      "0.40912443\n",
      "0.76500636\n",
      "0.99704885\n",
      "1.274686\n",
      "1.1583378\n",
      "1.714872\n",
      "1.1161664\n",
      "1.2563324\n",
      "0.9578129\n",
      "0.9148593\n",
      "0.7793797\n",
      "0.8456917\n",
      "0.75035393\n",
      "1.6689806\n",
      "1.7626104\n",
      "1.8287882\n",
      "1.8365847\n",
      "1.745274\n",
      "2.010011\n",
      "1.7565491\n",
      "1.2401944\n",
      "1.4111439\n",
      "2.1580749\n",
      "1.131766\n",
      "1.4037361\n",
      "1.7644402\n",
      "1.2587095\n",
      "1.5376766\n",
      "0.9013628\n",
      "1.6142124\n",
      "0.5871853\n",
      "1.2215029\n",
      "1.4404509\n",
      "1.4871606\n",
      "1.5446512\n",
      "1.9533561\n",
      "1.4653966\n",
      "1.1927626\n",
      "1.3850062\n",
      "1.5277712\n",
      "1.8912685\n",
      "1.1193869\n",
      "1.7841084\n",
      "1.3651781\n",
      "1.3797703\n",
      "1.4879639\n",
      "1.2729499\n",
      "0.8503292\n",
      "1.2162619\n",
      "0.9014025\n",
      "1.1617634\n",
      "0.6300469\n",
      "0.8273307\n",
      "0.7358489\n",
      "0.6471176\n",
      "0.3669049\n",
      "0.38416132\n",
      "0.19771701\n",
      "0.68074024\n",
      "0.037428506\n",
      "0.1704413\n",
      "0.15729927\n",
      "1.1564729\n",
      "1.1162504\n",
      "0.9260624\n",
      "1.2182195\n",
      "0.8023499\n",
      "1.1022906\n",
      "1.278159\n",
      "0.7805563\n",
      "1.5193262\n",
      "0.8890193\n",
      "1.0751662\n",
      "0.56737155\n",
      "0.8803767\n",
      "1.2720053\n",
      "0.92965233\n",
      "0.82522136\n",
      "0.43940115\n",
      "0.39850137\n",
      "0.5093252\n",
      "0.31452623\n",
      "1.5462754\n",
      "1.9080923\n",
      "0.8797474\n",
      "0.78929126\n",
      "0.9235878\n",
      "1.5305933\n",
      "0.9138443\n",
      "1.0210147\n",
      "1.52772\n",
      "0.701718\n",
      "1.4887488\n",
      "1.1586783\n",
      "1.4327934\n",
      "1.6906141\n",
      "1.4643551\n",
      "0.7884259\n",
      "1.1026027\n",
      "0.6152388\n",
      "0.7825426\n",
      "1.0905178\n",
      "1.3561847\n",
      "1.6087631\n",
      "1.6221606\n",
      "1.2283263\n",
      "1.0892235\n",
      "0.88049924\n",
      "1.0697329\n",
      "0.8052887\n",
      "0.53126204\n",
      "1.2061269\n",
      "1.0487541\n",
      "1.0802728\n",
      "1.4139274\n",
      "1.2089641\n",
      "0.8574109\n",
      "1.153707\n",
      "1.08886\n",
      "0.92570955\n",
      "0.7258464\n",
      "0.9749443\n",
      "0.62143886\n",
      "0.9172888\n",
      "0.8245505\n",
      "1.290766\n",
      "1.0542176\n",
      "0.536474\n",
      "0.79206824\n",
      "0.60364246\n",
      "0.55686843\n",
      "0.2500865\n",
      "0.3775912\n",
      "1.0117555\n",
      "0.07915653\n",
      "0.17265502\n",
      "0.32057297\n",
      "0.35379967\n",
      "0.12238389\n",
      "0.2655107\n",
      "0.09963125\n",
      "0.01641367\n",
      "0.39165404\n",
      "0.48711333\n",
      "1.2051939\n",
      "1.1266766\n",
      "1.4178903\n",
      "0.3446231\n",
      "0.82887995\n",
      "0.30371004\n",
      "0.8780176\n",
      "0.54166216\n",
      "0.868213\n",
      "0.796956\n",
      "1.5798409\n",
      "0.8556021\n",
      "0.6655487\n",
      "0.42998108\n",
      "0.46713036\n",
      "0.6223033\n",
      "0.7025343\n",
      "0.374543\n",
      "0.6018888\n",
      "0.8640982\n",
      "1.0731661\n",
      "1.095576\n",
      "0.7684889\n",
      "1.0544598\n",
      "0.5361765\n",
      "0.8015574\n",
      "0.7393904\n",
      "0.5521027\n",
      "0.8855507\n",
      "1.090596\n",
      "0.9748155\n",
      "1.191076\n",
      "1.4654126\n",
      "1.1886252\n",
      "0.7953427\n",
      "1.4107292\n",
      "1.0530722\n",
      "0.978786\n",
      "0.7264871\n",
      "0.82054025\n",
      "0.83162194\n",
      "0.7372708\n",
      "0.917497\n",
      "0.18213248\n",
      "1.3356869\n",
      "0.44338027\n",
      "1.065766\n",
      "0.7294606\n",
      "0.7864707\n",
      "0.9093396\n",
      "1.388557\n",
      "0.83513796\n",
      "0.74151343\n",
      "0.5857414\n",
      "0.9167509\n",
      "0.87164366\n",
      "0.65532184\n",
      "0.3364262\n",
      "0.8749806\n",
      "0.8437827\n",
      "1.0955765\n",
      "1.2035458\n",
      "0.48560095\n",
      "0.24033627\n",
      "0.30862126\n",
      "0.5435891\n",
      "0.321591\n",
      "0.748997\n",
      "0.6569776\n",
      "0.12312591\n",
      "0.40060097\n",
      "0.1823946\n",
      "0.06253508\n",
      "0.034019142\n",
      "0.056765087\n",
      "0.22288628\n",
      "0.46493277\n",
      "0.28827313\n",
      "0.28975862\n",
      "0.76205\n",
      "0.90139884\n",
      "0.29807323\n",
      "1.0235548\n",
      "0.49764127\n",
      "0.6739436\n",
      "0.1574026\n",
      "0.6585462\n",
      "0.38317978\n",
      "0.85284185\n",
      "0.5337397\n",
      "1.0469176\n",
      "0.8876041\n",
      "0.34193873\n",
      "0.54420793\n",
      "0.42233628\n",
      "0.31065583\n",
      "0.19247103\n",
      "0.17470632\n",
      "0.83295614\n",
      "0.8932142\n",
      "0.7228004\n",
      "1.1400197\n",
      "1.1981355\n",
      "0.7428156\n",
      "0.5723187\n",
      "0.46791333\n",
      "0.7793437\n",
      "0.45557538\n",
      "0.58807653\n",
      "0.99532855\n",
      "0.69724363\n",
      "0.7166225\n",
      "1.0350857\n",
      "0.78121156\n",
      "1.1576912\n",
      "0.5637714\n",
      "1.1093911\n",
      "1.2622048\n",
      "0.8720776\n",
      "0.63139486\n",
      "0.7669479\n",
      "0.56158096\n",
      "0.41153532\n",
      "0.36240745\n",
      "0.86326253\n",
      "0.6701652\n",
      "0.6462968\n",
      "0.9497382\n",
      "0.95726603\n",
      "1.2123127\n",
      "0.65619844\n",
      "0.9652942\n",
      "0.870401\n",
      "0.6645416\n",
      "0.8828386\n",
      "0.78904945\n",
      "0.6267189\n",
      "0.53021896\n",
      "0.42231655\n",
      "0.4996764\n",
      "1.125932\n",
      "0.5251366\n",
      "0.13485983\n",
      "0.46546644\n",
      "0.8814972\n",
      "0.720473\n",
      "0.46315902\n",
      "0.43426102\n",
      "0.51540387\n",
      "0.17384827\n",
      "0.47366172\n",
      "0.06754498\n",
      "0.15239978\n",
      "0.07764147\n",
      "0.058729686\n",
      "0.052318446\n",
      "0.050743006\n",
      "0.26018184\n",
      "0.22974718\n",
      "0.5807573\n",
      "0.31888804\n",
      "0.8901552\n",
      "0.47549826\n",
      "0.41113925\n",
      "0.84281796\n",
      "0.28410873\n",
      "0.70959675\n",
      "0.31916076\n",
      "0.5648002\n",
      "0.9175375\n",
      "0.56327325\n",
      "0.5408372\n",
      "0.58734524\n",
      "0.32736936\n",
      "0.3150917\n",
      "0.31233776\n",
      "0.30014175\n",
      "0.31723976\n",
      "0.7244506\n",
      "0.5240628\n",
      "0.5643739\n",
      "0.40791494\n",
      "0.57553095\n",
      "0.37383914\n",
      "0.6344865\n",
      "0.59075224\n",
      "0.40859213\n",
      "0.2855149\n",
      "0.8305523\n",
      "0.44128537\n",
      "0.70671237\n",
      "0.5690495\n",
      "0.94044006\n",
      "0.8487841\n",
      "0.74519604\n",
      "0.98573816\n",
      "0.56373155\n",
      "0.67162603\n",
      "0.57523143\n",
      "0.5365633\n",
      "1.0791705\n",
      "0.7410451\n",
      "0.53527826\n",
      "0.71762455\n",
      "1.0853701\n",
      "0.5113579\n",
      "0.29796332\n",
      "0.79495424\n",
      "0.4202035\n",
      "0.8232697\n",
      "0.5893442\n",
      "0.3765704\n",
      "0.7401413\n",
      "0.7768737\n",
      "0.4476243\n",
      "1.0055633\n",
      "0.55839515\n",
      "0.6224303\n",
      "0.59828985\n",
      "0.7271229\n",
      "0.5688299\n",
      "0.459117\n",
      "0.29995418\n",
      "0.22429779\n",
      "0.5961443\n",
      "0.3485185\n",
      "0.3592881\n",
      "0.050392825\n",
      "0.42846864\n",
      "0.34474957\n",
      "0.35339722\n",
      "0.089345396\n",
      "0.028119585\n",
      "0.022893142\n",
      "0.04459942\n",
      "0.65943635\n",
      "0.09341496\n",
      "0.07653026\n",
      "0.3424818\n",
      "0.70892024\n",
      "0.611099\n",
      "0.2058682\n",
      "1.0977004\n",
      "0.09718643\n",
      "0.39545518\n",
      "0.107326284\n",
      "0.7785896\n",
      "0.10742704\n",
      "0.47548717\n",
      "0.78208804\n",
      "0.23036149\n",
      "0.6044763\n",
      "0.67263454\n",
      "0.091318965\n",
      "0.5683781\n",
      "0.27763495\n",
      "0.38919324\n",
      "0.31417495\n",
      "0.4837362\n",
      "0.73599017\n",
      "0.7709695\n",
      "0.36727864\n",
      "0.8709513\n",
      "0.31548133\n",
      "0.245262\n",
      "0.1924765\n",
      "0.26636156\n",
      "0.21414478\n",
      "0.4622708\n",
      "0.6912824\n",
      "0.8097067\n",
      "0.79678375\n",
      "0.3420706\n",
      "0.81495726\n",
      "0.6191045\n",
      "0.38735205\n",
      "0.7082182\n",
      "0.6034861\n",
      "0.36807892\n",
      "0.89480364\n",
      "0.62182724\n",
      "0.5954715\n",
      "0.33038193\n",
      "0.2192462\n",
      "0.8002504\n",
      "0.2448806\n",
      "0.35628828\n",
      "0.57343656\n",
      "0.7752134\n",
      "0.47005415\n",
      "0.36505783\n",
      "0.34294075\n",
      "0.43423787\n",
      "0.6602882\n",
      "0.7849492\n",
      "0.90009797\n",
      "0.22413842\n",
      "0.4896551\n",
      "0.33751768\n",
      "0.4446109\n",
      "0.61844695\n",
      "0.68802804\n",
      "0.58156496\n",
      "0.10182206\n",
      "0.5761069\n",
      "0.095082104\n",
      "0.13616917\n",
      "0.49558407\n",
      "0.02820924\n",
      "0.29066736\n",
      "0.23518169\n",
      "0.012753499\n",
      "0.004977393\n",
      "0.020995982\n",
      "0.057710357\n",
      "0.012785802\n",
      "0.044688914\n",
      "0.19829714\n",
      "0.43760395\n",
      "0.29372546\n",
      "0.56863225\n",
      "0.2511714\n",
      "0.29674754\n",
      "0.4296534\n",
      "0.3217508\n",
      "0.47244254\n",
      "0.037055396\n",
      "0.43251118\n",
      "0.56119114\n",
      "0.59990376\n",
      "0.42041844\n",
      "0.8776037\n",
      "0.513422\n",
      "0.73228854\n",
      "0.11395677\n",
      "0.47797704\n",
      "0.55178225\n",
      "0.4600528\n",
      "0.21507296\n",
      "0.7397971\n",
      "0.33248025\n",
      "0.7231256\n",
      "0.47095713\n",
      "0.9304632\n",
      "0.34971341\n",
      "0.5022181\n",
      "0.3798698\n",
      "0.2246441\n",
      "0.48281297\n",
      "0.6712646\n",
      "0.7356572\n",
      "0.86920965\n",
      "0.47346878\n",
      "0.24115781\n",
      "0.6094729\n",
      "0.5187385\n",
      "0.49805966\n",
      "0.75798595\n",
      "0.27799731\n",
      "0.32243273\n",
      "0.45495754\n",
      "0.59899557\n",
      "0.5521749\n",
      "0.46820584\n",
      "0.90969056\n",
      "0.48709497\n",
      "0.11593829\n",
      "1.1885859\n",
      "0.62842065\n",
      "0.51131046\n",
      "0.41121095\n",
      "0.6741274\n",
      "0.44411808\n",
      "0.5067604\n",
      "0.1670806\n",
      "0.57354057\n",
      "0.20593286\n",
      "0.3193023\n",
      "0.39675677\n",
      "0.103468165\n",
      "0.1255682\n",
      "0.27338815\n",
      "0.29580325\n",
      "0.08762301\n",
      "0.40102425\n",
      "0.3905125\n",
      "0.21673103\n",
      "0.36040968\n",
      "0.42433038\n",
      "0.079498604\n",
      "0.13176675\n",
      "0.016583797\n",
      "0.001230214\n",
      "0.006671955\n",
      "0.26419562\n",
      "0.092789665\n",
      "0.11284889\n",
      "0.00092377653\n",
      "0.019331852\n",
      "0.2756466\n",
      "0.34594384\n",
      "0.17799449\n",
      "0.7072547\n",
      "0.40627378\n",
      "0.0789416\n",
      "0.44423276\n",
      "0.27427915\n",
      "0.12608692\n",
      "1.0247109\n",
      "0.35833362\n",
      "0.375709\n",
      "0.6056173\n",
      "0.3052396\n",
      "0.1410815\n",
      "0.25088406\n",
      "0.17072019\n",
      "0.38667238\n",
      "0.30815244\n",
      "0.33060223\n",
      "0.6771923\n",
      "0.27401465\n",
      "0.72760755\n",
      "0.6182919\n",
      "0.23526335\n",
      "0.05984957\n",
      "0.24154143\n",
      "0.3566299\n",
      "0.3725408\n",
      "0.23904288\n",
      "0.55030954\n",
      "0.6365925\n",
      "0.5357808\n",
      "0.38649803\n",
      "0.31676823\n",
      "0.5656171\n",
      "0.3293386\n",
      "0.2204084\n",
      "0.25537658\n",
      "0.23664775\n",
      "0.21858402\n",
      "0.3055489\n",
      "0.47258854\n",
      "0.2524729\n",
      "0.36750644\n",
      "0.3906198\n",
      "0.3026445\n",
      "0.6757852\n",
      "0.43908986\n",
      "0.23046994\n",
      "0.31820297\n",
      "0.67979044\n",
      "0.4643755\n",
      "0.16893065\n",
      "0.24283966\n",
      "0.24418762\n",
      "0.43930483\n",
      "0.1284711\n",
      "0.1975214\n",
      "0.4388174\n",
      "0.22254267\n",
      "0.43519562\n",
      "0.34552217\n",
      "0.25584048\n",
      "0.0664116\n",
      "0.015284826\n",
      "0.44018596\n",
      "0.32892504\n",
      "0.042424724\n",
      "0.19342194\n",
      "0.38001007\n",
      "0.0019131623\n",
      "0.028206915\n",
      "0.00091257226\n",
      "0.011369884\n",
      "0.4674035\n",
      "0.0007922022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010705427\n",
      "0.0003691101\n",
      "0.3689828\n",
      "0.476052\n",
      "0.47964525\n",
      "0.031044146\n",
      "0.51103085\n",
      "0.17868923\n",
      "0.28634658\n",
      "0.03319425\n",
      "0.43149298\n",
      "0.2618402\n",
      "0.31884742\n",
      "Validation accuracy after fune tuning for epoch 790 : 0.8199999928474426\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph,config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    images,labels = read_training_data()\n",
    "    valid_images,valid_labels = read_validation_data()\n",
    "    \n",
    "    init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())  \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    init_fn(sess)\n",
    "    sess.run(fc8_init)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    print(\"Started Training ... !\")\n",
    "\n",
    "#     epoch=0\n",
    "#     try:\n",
    "#         while not coord.should_stop():\n",
    "#             img,lbl = sess.run([images,labels])\n",
    "#             img = img.astype(np.uint8)\n",
    "#             # print(\"Next batch : {}\".format(img.shape,lbl.shape))\n",
    "#             sess.run(fc8_train_op,feed_dict={x:img,y:lbl})\n",
    "#             print(\"Loss : {:.2f}\".format(sess.run(loss,feed_dict={x:img,y:lbl})))\n",
    "#             epoch+=1\n",
    "#     except tf.errors.OutOfRangeError as e:\n",
    "#         coord.request_stop(e)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        img,lbl = sess.run([images,labels])\n",
    "        img = img.astype(np.uint8)\n",
    "        # print(\"Next batch : {}\".format(img.shape,lbl.shape))\n",
    "        sess.run(fc8_train_op,feed_dict={x:img,y:lbl})\n",
    "        \n",
    "    val_img,val_lbl = sess.run([valid_images,valid_labels])\n",
    "    val_img = val_img.astype(np.uint8)\n",
    "    print(\"Validation Accuracy after retraining for {} epoch : {:.2f}\".format(epoch+1,sess.run(accuracy,feed_dict={x:val_img,y:val_lbl})))\n",
    "\n",
    "\n",
    "    epoch=0\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            img,lbl = sess.run([images,labels])\n",
    "            sess.run(full_train_op,feed_dict={x:img,y:lbl})\n",
    "            print(sess.run(loss,feed_dict={x:img,y:lbl}))\n",
    "            epoch+=1\n",
    "    except tf.errors.OutOfRangeError as e:\n",
    "        coord.request_stop(e)\n",
    "        \n",
    "    val_img,val_lbl = sess.run([valid_images,valid_labels])\n",
    "    print(\"Validation accuracy after fune tuning for epoch {} : {}\".format(epoch,sess.run(accuracy,feed_dict={x:val_img,y:val_lbl})))  \n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
